{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--acc_rate ACC_RATE] [--epochs EPOCHS]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--batchSize BATCHSIZE]\n",
      "                             [--nb_unroll_blocks NB_UNROLL_BLOCKS]\n",
      "                             [--nb_res_blocks NB_RES_BLOCKS]\n",
      "                             [--CG_Iter CG_ITER] [--data_opt DATA_OPT]\n",
      "                             [--nrow_GLOB NROW_GLOB] [--ncol_GLOB NCOL_GLOB]\n",
      "                             [--ncoil_GLOB NCOIL_GLOB]\n",
      "                             [--mask_type {Gaussian,Uniform}] [--rho RHO]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9040 --control=9038 --hb=9037 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"ba3d151c-3084-49e6-8f0d-5357fa046a04\" --shell=9039 --transport=\"tcp\" --iopub=9041 --f=/home/jc_350/.local/share/jupyter/runtime/kernel-v2-1335648dqg1zY80VbSr.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jc_350/.conda/envs/ssdu/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import h5py as h5\n",
    "#import utils\n",
    "from preprocess import loadmat_cart, step_gen, get_enum_list\n",
    "import tf_utils\n",
    "import parser_ops\n",
    "import masks.ssdu_masks as ssdu_masks\n",
    "import UnrollNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--acc_rate ACC_RATE] [--epochs EPOCHS]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--batchSize BATCHSIZE]\n",
      "                             [--nb_unroll_blocks NB_UNROLL_BLOCKS]\n",
      "                             [--nb_res_blocks NB_RES_BLOCKS]\n",
      "                             [--CG_Iter CG_ITER] [--data_opt DATA_OPT]\n",
      "                             [--nrow_GLOB NROW_GLOB] [--ncol_GLOB NCOL_GLOB]\n",
      "                             [--ncoil_GLOB NCOIL_GLOB]\n",
      "                             [--mask_type {Gaussian,Uniform}] [--rho RHO]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9040 --control=9038 --hb=9037 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"ba3d151c-3084-49e6-8f0d-5357fa046a04\" --shell=9039 --transport=\"tcp\" --iopub=9041 --f=/home/jc_350/.local/share/jupyter/runtime/kernel-v2-1335648dqg1zY80VbSr.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jc_350/.conda/envs/ssdu/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import tf_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = parser_ops.get_parser()\n",
    "args = parser.parse_args()\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "save_dir ='saved_models'\n",
    "directory = os.path.join(save_dir, 'SSDU_' + args.data_opt + '_' +str(args.epochs)+'Epochs_Rate'+ str(args.acc_rate) +\\\n",
    "                         '_' + str(args.nb_unroll_blocks) + 'Unrolls_' + args.mask_type+'Selection' )\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "print('\\n create a test model for the testing')\n",
    "test_graph_generator = tf_utils.test_graph(directory)\n",
    "\n",
    "#..............................................................................\n",
    "start_time = time.time()\n",
    "print('.................SSDU Training.....................')\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .......................Load the Data..........................................\n",
    "print('\\n Loading ', args.data_opt, ' data, acc rate : ', args.acc_rate, ', mask type :', args.mask_type)\n",
    "mask_dir = '/home/jc_350/zfan0804_712/Zhehao/Accelerated-VWI-Mask/mask_2x3_grappa.mat'\n",
    "\n",
    "# %% kspace and sensitivity maps are assumed to be in .h5 format and mask is assumed to be in .mat\n",
    "# Users can change these formats based on their dataset\n",
    "original_mask = sio.loadmat(mask_dir)['mask']\n",
    "\n",
    "\n",
    "# %%  zeropadded outer edges of k-space with no signal- check github readme file for explanation for further explanations\n",
    "# for coronal PD dataset, first 17 and last 16 columns of k-space has no signal\n",
    "# in the training mask we set corresponding columns as 1 to ensure data consistency\n",
    "\n",
    "# %% set the batch size\n",
    "# total_batch = int(np.floor(np.float32(nw_input.shape[0]) / (args.batchSize)))\n",
    "# kspaceP = tf.placeholder(tf.float32, shape=(None, None, None, None, 2), name='refkspace')\n",
    "# sens_mapsP = tf.placeholder(tf.complex64, shape=(None, None, None, None), name='sens_maps')\n",
    "# trn_maskP = tf.placeholder(tf.complex64, shape=(None, None, None), name='trn_mask')\n",
    "# loss_maskP = tf.placeholder(tf.complex64, shape=(None, None, None), name='loss_mask')\n",
    "# nw_inputP = tf.placeholder(tf.float32, shape=(None, args.nrow_GLOB, args.ncol_GLOB, 2), name='nw_input')\n",
    "\n",
    "print('Getting list of trainning files')\n",
    "enumerate_trn_list = get_enum_list('dcm_tags_09_19_22.csv',tag='Train')\n",
    "print('Getting list of trainning files done')\n",
    "ssdu_masker = ssdu_masks.ssdu_masks()\n",
    "total_batch = np.shape(enumerate_trn_list)[0]\n",
    "dataset = tf.data.Dataset.from_generator(lambda: step_gen(enumerate_trn_list, original_mask, ssdu_masker,shuffle=True),\n",
    "                                         output_types=((tf.float32, tf.float32, tf.complex64,\n",
    "                                                           tf.complex64, tf.complex64))\n",
    "                                        )\n",
    "dataset = dataset.batch(args.batchSize)\n",
    "dataset = dataset.prefetch(args.batchSize)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "ref_kspace_tensor, nw_input_tensor, sens_maps_tensor, trn_mask_tensor, loss_mask_tensor = iterator.get_next('getNext')\n",
    "print(ref_kspace_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% make training model\n",
    "nw_output_img, nw_output_kspace, *_ = UnrollNet.UnrolledNet(nw_input_tensor, sens_maps_tensor, trn_mask_tensor, loss_mask_tensor).model\n",
    "scalar = tf.constant(0.5, dtype=tf.float32)\n",
    "loss = tf.multiply(scalar, tf.norm(ref_kspace_tensor - nw_output_kspace) / tf.norm(ref_kspace_tensor)) + \\\n",
    "       tf.multiply(scalar, tf.norm(ref_kspace_tensor - nw_output_kspace, ord=1) / tf.norm(ref_kspace_tensor, ord=1))\n",
    "\n",
    "all_trainable_vars = tf.reduce_sum([tf.reduce_prod(v.shape) for v in tf.trainable_variables()])\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=args.learning_rate).minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "sess_trn_filename = os.path.join(directory, 'model')\n",
    "totalLoss = []\n",
    "avg_cost = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssdu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
